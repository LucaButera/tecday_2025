{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import copy\n",
    "\n",
    "from src.data import PeakWeatherTorchDataset, test_model, plot_predictions\n",
    "from src.model import train_model, MLPModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Scegliere la finestra di osservazione e l'orizzonte di previsione\n",
    "Vogliamo prevedere le prossime 24 ore, come con il modello ARIMA.\n",
    "\n",
    "I modelli di deep learning spesso richiedono una finestra di osservazione più lunga per catturare le dinamiche temporali.\n",
    "Scegliamo, per esempio, una finestra di 48 ore (2 giorni)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 24  # Previsione a 24 ore per confrontare con ARIMA\n",
    "window = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Dividere il dataset in training, validation e test set\n",
    "Creiamo tre dataset distinti per l'addestramento, la validazione e il test.\n",
    "\n",
    "Il dataset di validazione viene utilizzato durante l'addestramento per monitorare le prestazioni del modello su dati non visti e stabilire quando fermare l'addestramento.\n",
    "\n",
    "#### Domanda\n",
    "Noti qualche differenza con la suddivisione del dataset rispetto a quella utilizzata per ARIMA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PeakWeatherTorchDataset(window=window, horizon=horizon)\n",
    "val_dataset = copy(train_dataset)\n",
    "val_dataset.mode = \"val\"\n",
    "test_dataset = copy(train_dataset)\n",
    "test_dataset.mode = \"test\"\n",
    "\n",
    "# Creiamo i DataLoader per ciascun dataset\n",
    "batch_size = 8192\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Scegliamo gli iperparametri della rete neurale\n",
    "- hidden_size: numero di unità in ogni layer, larghezza della rete\n",
    "- num_layers: numero di layer, profondità della rete\n",
    "- lr: learning rate, velocità di apprendimento\n",
    "- epochs: numero di volte in cui l'algoritmo vede l'intero dataset di training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 16\n",
    "num_layers = 2\n",
    "lr = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Creiamo la rete neurale e addestriamola\n",
    "Utilizziamo un modello MLP (Multi-Layer Perceptron) per la previsione della temperatura.\n",
    "Questo modello prende in input una finestra di osservazioni e produce un'uscita per l'orizzonte di previsione specificato.\n",
    "\n",
    "Gli MLP sono il tipo più classico di rete neurale.\n",
    "Possono approssimare funzioni complesse tramite una sequenza di trasformazioni lineari e non lineari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPModel(window=window, horizon=horizon, hidden_size=\"???\", num_layers=\"???\")\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    lr=\"???\",\n",
    "    epochs=\"???\",\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Testiamo il modello sui dati di test\n",
    "Calcoliamo l'errore medio assoluto (MAE) del modello sui dati di test.\n",
    "\n",
    "#### Domande\n",
    "- Come si confronta questo valore con quello ottenuto con il modello ARIMA?\n",
    "- I due valori sono direttamente confrontabili? Perché sì o perché no? (Suggerimento: quali serie temporali stiamo predicendo?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = test_model(model=\"???\", test_loader=test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Visualizziamo alcune previsioni del modello\n",
    "Tracciamo alcune previsioni del modello sui dati di test per valutarne le prestazioni visivamente.\n",
    "\n",
    "Puoi scambiare il numero di campioni visualizzati modificando il parametro `num_samples`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(model=\"???\", test_dataset=test_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "#### Esercizio\n",
    "- Prova a variare gli iperparametri del modello (window, hidden_size, num_layers, lr, epochs) e osserva come cambiano le prestazioni del modello.\n",
    "- Cerca di migliorare il MAE ottenuto e di ottenere previsioni più accurate.\n",
    "- Documenta le tue modifiche e i risultati ottenuti.\n",
    "\n",
    "**Consiglio**: Modifica un iperparametro alla volta per capire meglio il suo impatto sulle prestazioni del modello.\n",
    "Mantieni i valori sotto queste soglie per evitare lunghi tempi di addestramento:\n",
    "- hidden_size ≤ 64\n",
    "- num_layers ≤ 4\n",
    "- epochs ≤ 20\n",
    "- window ≤ 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
