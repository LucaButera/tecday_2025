{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from peakweather.dataset import PeakWeatherDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from copy import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PWDataset(Dataset):\n",
    "\n",
    "    Sample = namedtuple(\"Sample\", [\"x\", \"y\", \"mu\", \"sigma\"])\n",
    "\n",
    "    def __init__(self, window: int, horizon: int, parameter: str = \"temperature\"):\n",
    "        ds = PeakWeatherDataset(\n",
    "            root=None,\n",
    "            compute_uv=False,\n",
    "            station_type=\"meteo_station\",\n",
    "            freq=\"h\",\n",
    "            aggregation_methods={'temperature': 'mean'},\n",
    "        )\n",
    "        self.mode = \"train\"\n",
    "        self.window = window\n",
    "        self.horizon = horizon\n",
    "        train, mask = ds.get_observations(parameters=parameter, first_date=\"2020-01-01\", last_date=\"2020-11-30\", as_numpy=True, return_mask=True)\n",
    "        good_stations = (mask.sum(axis=0) > 0).squeeze()\n",
    "        self.data = {\n",
    "            \"train\": train[:, good_stations].squeeze(),\n",
    "            \"val\": ds.get_observations(parameters=parameter, first_date=\"2020-12-01\", last_date=\"2020-12-31\", as_numpy=True)[:, good_stations].squeeze(),\n",
    "            \"test\": ds.get_observations(parameters=parameter, first_date=\"2021-01-01\", last_date=\"2021-01-31\", as_numpy=True)[:, good_stations].squeeze(),\n",
    "        }\n",
    "        self.scaling_params = {\"mu\": self.data[\"train\"].mean(axis=0), \"sigma\": self.data[\"train\"].std(axis=0)}\n",
    "        for mode in [\"train\", \"val\", \"test\"]:\n",
    "            self.data[mode] = (self.data[mode] - self.scaling_params[\"mu\"]) / self.scaling_params[\"sigma\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data[self.mode].shape[0] - self.window - self.horizon) * self.data[self.mode].shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        n, t = divmod(idx, (self.data[self.mode].shape[0] - self.window - self.horizon))\n",
    "        x = self.data[self.mode][t:t + self.window, n]\n",
    "        y = self.data[self.mode][t + self.window:t + self.window + self.horizon, n]\n",
    "        mu = self.scaling_params[\"mu\"][n]\n",
    "        sigma = self.scaling_params[\"sigma\"][n]\n",
    "        return self.Sample(\n",
    "            x=torch.tensor(x, dtype=torch.float32),\n",
    "            y=torch.tensor(y, dtype=torch.float32),\n",
    "            mu=torch.tensor(mu, dtype=torch.float32),\n",
    "            sigma=torch.tensor(sigma, dtype=torch.float32),\n",
    "        )\n",
    "\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, horizon: int, hidden_size: int = 16, num_layers: int = 2, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.gru = torch.nn.GRU(input_size=1, hidden_size=hidden_size, batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "        self.fc = torch.nn.Linear(in_features=hidden_size, out_features=horizon)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.unsqueeze(-1)  # add feature dim\n",
    "        _, h = self.gru(x)\n",
    "        out = self.fc(h[-1].squeeze(0))\n",
    "        return out\n",
    "\n",
    "class MLPModel(torch.nn.Module):\n",
    "    def __init__(self, window: int, horizon: int, hidden_size: int = 16, num_layers: int = 2, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for i in range(num_layers):\n",
    "            layers.append(torch.nn.Linear(in_features=window if i == 0 else hidden_size, out_features=hidden_size))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            if dropout > 0.0:\n",
    "                layers.append(torch.nn.Dropout(p=dropout))\n",
    "        self.mlp = torch.nn.Sequential(*layers)\n",
    "        self.fc = torch.nn.Linear(in_features=hidden_size, out_features=horizon)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        h = self.mlp(x)\n",
    "        out = self.fc(h)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model: torch.nn.Module, lr: float, epochs: int, train_loader: DataLoader, val_loader: DataLoader) ->torch.nn.Module:\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_train = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(batch.x)\n",
    "            loss = criterion(preds, batch.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train += loss.item()\n",
    "        avg_train = total_train / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        total_val = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                preds = model(batch.x)\n",
    "                loss = criterion(preds, batch.y)\n",
    "                total_val += loss.item()\n",
    "        avg_val = total_val / len(val_loader)\n",
    "\n",
    "        # Save best model\n",
    "        if avg_val < best_val_loss:\n",
    "            best_val_loss = avg_val\n",
    "            best_state = model.state_dict()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train: {avg_train:.4f} | Val: {avg_val:.4f}\")\n",
    "\n",
    "    # Restore best parameters\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"âœ… Restored best model (val loss = {best_val_loss:.4f})\")\n",
    "    return model\n",
    "\n",
    "def test_model(model: torch.nn.Module, test_loader: DataLoader) ->float:\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    model.eval()\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            preds = model(batch.x)\n",
    "            preds_rescaled = preds * batch.sigma.unsqueeze(-1) + batch.mu.unsqueeze(-1)\n",
    "            y_rescaled = batch.y * batch.sigma.unsqueeze(-1) + batch.mu.unsqueeze(-1)\n",
    "            loss = criterion(preds_rescaled, y_rescaled)\n",
    "            total_test += loss.item()\n",
    "    avg_test = total_test / len(test_loader)\n",
    "    print(f\"Test MAE: {avg_test:.4f}\")\n",
    "    return avg_test\n",
    "\n",
    "def plot_predictions(model: torch.nn.Module, test_dataset: Dataset, num_samples: int = 5):\n",
    "    model.eval()\n",
    "    fig, axs = plt.subplots(num_samples, 1, figsize=(10, num_samples * 3))\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            n = torch.randint(0, len(test_dataset), (1,)).item()\n",
    "            sample = test_dataset[n]\n",
    "            preds = model(sample.x.unsqueeze(0)).squeeze(0).numpy()\n",
    "            # Rescale predictions and ground truth\n",
    "            preds_rescaled = preds * sample.sigma.numpy() + sample.mu.numpy()\n",
    "            y_rescaled = sample.y.numpy() * sample.sigma.numpy() + sample.mu.numpy()\n",
    "            axs[i].plot(range(len(sample.x)), sample.x.numpy() * sample.sigma.numpy() + sample.mu.numpy(), label=\"input window\")\n",
    "            axs[i].plot(range(len(sample.x), len(sample.x) + len(y_rescaled)), y_rescaled, label=\"true horizon\")\n",
    "            axs[i].plot(range(len(sample.x), len(sample.x) + len(preds_rescaled)), preds_rescaled, label=\"forecast\")\n",
    "            axs[i].legend()\n",
    "            axs[i].set_title(f\"Sample {n}\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select window and horizon length\n",
    "window, horizon = 96, 24\n",
    "# Create datasets\n",
    "train_dataset = PWDataset(window=window, horizon=horizon, parameter=\"temperature\")\n",
    "val_dataset = copy(train_dataset)\n",
    "val_dataset.mode = \"val\"\n",
    "test_dataset = copy(train_dataset)\n",
    "test_dataset.mode = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 8192\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GRUModel(horizon=horizon, hidden_size=8, num_layers=2, dropout=0.0)\n",
    "model = MLPModel(window=window, horizon=horizon, hidden_size=16, num_layers=2, dropout=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(\n",
    "    model=model,\n",
    "    lr=0.001,\n",
    "    epochs=5,\n",
    "    train_loader=train_dataloader,\n",
    "    val_loader=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = test_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(model, test_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
